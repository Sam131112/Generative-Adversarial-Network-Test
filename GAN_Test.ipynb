{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam131112/Generative-Adversarial-Network-Test/blob/master/GAN_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIv0RpuXgEaX",
        "colab_type": "text"
      },
      "source": [
        "### In this NoteBook I try to generate fake samples from a  standard normal distribution from a noise distribution (Uniform Distribution) using generative adversarial networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqmGB1Z_ev-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as _data\n",
        "#import matplotlib.pyplot as plt\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions.uniform import Uniform\n",
        "m = Normal(torch.tensor([2.0]),torch.tensor([0.5]))\n",
        "m1 = Uniform(torch.tensor([0.0]),torch.tensor([0.1]))\n",
        "import torch.nn\n",
        "import torch.optim\n",
        "from torch.autograd.variable import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfG3L6L-fJxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3798673a-438a-4ff2-9fba-d22558ba5ac7"
      },
      "source": [
        "data = []\n",
        "\n",
        "\n",
        "for _ in range(100000):\n",
        "        data.append(m.sample())\n",
        "\n",
        "\n",
        "def noise(size):\n",
        "    _data = np.random.standard_normal(size)\n",
        "\n",
        "    temp = torch.Tensor(_data)\n",
        "    if torch.cuda.is_available():\n",
        "      return temp.view(-1,1).cuda()\n",
        "    else:\n",
        "      return temp.view(-1,1)\n",
        "\n",
        "\n",
        "data = torch.Tensor(data)\n",
        "data = _data.TensorDataset(data)\n",
        "data_loader = _data.DataLoader(data,batch_size=1000,shuffle=True)\n",
        "print(len(data_loader))\n",
        "\n",
        "for n_batch,batch in enumerate(data_loader):\n",
        "    #print(n_batch,batch[0].size(0))\n",
        "    pass\n",
        "\n",
        "d = batch[0].view(-1,1)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn1AudVPfXXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator,self).__init__()\n",
        "        n_features = 1\n",
        "        n_out = 1\n",
        "        self.hidden0 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(n_features,16),\n",
        "                torch.nn.LeakyReLU(0.2),\n",
        "                torch.nn.Dropout(0.2)\n",
        "        )\n",
        "        self.hidden1 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(16,4),\n",
        "                torch.nn.LeakyReLU(0.2),\n",
        "                torch.nn.Dropout(0.2)\n",
        "        )\n",
        "        self.hidden3 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(4,n_out),\n",
        "                torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.hidden0(x)\n",
        "        #print(\"Inter 1\",x.shape)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet,self).__init__()\n",
        "        n_features = 1\n",
        "        n_out = 1\n",
        "\n",
        "        self.hidden0 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(n_features,16),\n",
        "                torch.nn.LeakyReLU(0.2)\n",
        "                )\n",
        "\n",
        "        self.hidden1 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(16,4),\n",
        "                torch.nn.LeakyReLU(0.2)\n",
        "                )\n",
        "        self.hidden2 = torch.nn.Sequential(\n",
        "                torch.nn.Linear(4,1),\n",
        "                torch.nn.Tanh()\n",
        "                )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "discriminator = Discriminator()\n",
        "generator = GeneratorNet()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MF4xHFrfjK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_optimizer = torch.optim.Adam(discriminator.parameters(),lr=0.01)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(),lr=0.01)\n",
        "\n",
        "loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()\n",
        "\n",
        "\n",
        "\n",
        "def real_target(size):\n",
        "    data = Variable(torch.ones(size,1))\n",
        "    if torch.cuda.is_available():\n",
        "      return data.cuda()\n",
        "    else:\n",
        "      return data\n",
        "\n",
        "def zeros_target(size):\n",
        "    data = Variable(torch.zeros(size,1))\n",
        "    if torch.cuda.is_available():\n",
        "      return data.cuda()\n",
        "    else:\n",
        "      return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbiH9sxlfrVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(opt,real_data,fake_data):\n",
        "    N = real_data.size(0)\n",
        "    opt.zero_grad()\n",
        "    pred_real = discriminator(real_data)\n",
        "    error_r = loss(pred_real,real_target(N))\n",
        "    error_r.backward()\n",
        "    pred_fake = discriminator(fake_data)\n",
        "    error_f = loss(pred_fake,zeros_target(N))\n",
        "    opt.step()\n",
        "    return error_r+error_f,pred_real,pred_fake\n",
        "\n",
        "def train_generator(opt,fake_data):\n",
        "    N = fake_data.size(0)\n",
        "    opt.zero_grad()\n",
        "    pred = discriminator(fake_data)\n",
        "    error = loss(pred,real_target(N))\n",
        "    error.backward()\n",
        "    opt.step()\n",
        "    return error\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPF8ewd5f14B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "\n",
        " num_epochs = 1000\n",
        "\n",
        " for epoch in range(num_epochs):\n",
        "    for n_batch,batch in enumerate(data_loader):\n",
        "        d = batch[0].view(-1,1)\n",
        "        N = d.size(0)\n",
        "        real_data = Variable(d)\n",
        "        if torch.cuda.is_available():\n",
        "          real_data = real_data.cuda()\n",
        "        fake_data = generator(noise(N))\n",
        "        d_er,d_pred_rl,p_pred_fk = train_discriminator(d_optimizer,real_data,fake_data)\n",
        "        fake_data = generator(noise(N))\n",
        "        g_error = train_generator(g_optimizer,fake_data)\n",
        "    if epoch%50 == 0:\n",
        "        fake_data = generator(noise(N))\n",
        "        #print(N,fake_data)\n",
        "        print(epoch,torch.mean(fake_data,0),torch.std(fake_data,0),torch.mean(d,0),torch.std(d,0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0La-Vkb7f31v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWjRUgWShjyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = np.random.uniform(0,1,10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUOO5MzT4Vzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = noise(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiQYdCNJ4eff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b700bb01-26ba-44c5-cbef-cb810e1a28e2"
      },
      "source": [
        "main()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor([0.9999], grad_fn=<MeanBackward2>) tensor([9.2699e-05], grad_fn=<StdBackward1>) tensor([2.0185]) tensor([0.5112])\n",
            "50 tensor([0.9999], grad_fn=<MeanBackward2>) tensor([4.7587e-05], grad_fn=<StdBackward1>) tensor([2.0119]) tensor([0.5006])\n",
            "100 tensor([0.9999], grad_fn=<MeanBackward2>) tensor([4.3685e-05], grad_fn=<StdBackward1>) tensor([2.0102]) tensor([0.5167])\n",
            "150 tensor([0.9999], grad_fn=<MeanBackward2>) tensor([4.0316e-05], grad_fn=<StdBackward1>) tensor([1.9725]) tensor([0.5053])\n",
            "200 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9402e-05], grad_fn=<StdBackward1>) tensor([1.9852]) tensor([0.5194])\n",
            "250 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8527e-05], grad_fn=<StdBackward1>) tensor([1.9938]) tensor([0.5011])\n",
            "300 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9858e-05], grad_fn=<StdBackward1>) tensor([2.0022]) tensor([0.5014])\n",
            "350 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9457e-05], grad_fn=<StdBackward1>) tensor([2.0035]) tensor([0.5300])\n",
            "400 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8815e-05], grad_fn=<StdBackward1>) tensor([2.0013]) tensor([0.4966])\n",
            "450 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9447e-05], grad_fn=<StdBackward1>) tensor([2.0247]) tensor([0.4998])\n",
            "500 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8921e-05], grad_fn=<StdBackward1>) tensor([2.0003]) tensor([0.4859])\n",
            "550 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8312e-05], grad_fn=<StdBackward1>) tensor([2.0271]) tensor([0.4963])\n",
            "600 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9115e-05], grad_fn=<StdBackward1>) tensor([1.9966]) tensor([0.5099])\n",
            "650 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8937e-05], grad_fn=<StdBackward1>) tensor([1.9630]) tensor([0.4948])\n",
            "700 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9709e-05], grad_fn=<StdBackward1>) tensor([2.0114]) tensor([0.5086])\n",
            "750 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9346e-05], grad_fn=<StdBackward1>) tensor([2.0109]) tensor([0.4873])\n",
            "800 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9534e-05], grad_fn=<StdBackward1>) tensor([1.9884]) tensor([0.5101])\n",
            "850 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9048e-05], grad_fn=<StdBackward1>) tensor([2.0064]) tensor([0.5232])\n",
            "900 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.9220e-05], grad_fn=<StdBackward1>) tensor([1.9902]) tensor([0.5073])\n",
            "950 tensor([1.0000], grad_fn=<MeanBackward2>) tensor([3.8086e-05], grad_fn=<StdBackward1>) tensor([2.0058]) tensor([0.5126])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upLc8mGc5j9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}